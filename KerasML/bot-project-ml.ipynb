{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install pypandoc\n!pip install --upgrade protobuf tf2onnx keras2onnx onnxruntime tensorflow keras numpy azureml-sdk[automl]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "SUBSCRIPTION_ID='<Add your subs. id>'\nWORKSPACE='<Add your workspace name>'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Access Azure workspace\nfrom azureml.core import Workspace\ntry:\n    ws = Workspace(subscription_id = SUBSCRIPTION_ID, resource_group = WORKSPACE, workspace_name = WORKSPACE)\n    # write the details of the workspace to a configuration file to the notebook library\n    ws.write_config()\n    print(\"Workspace configuration succeeded.\")\nexcept:\n    print(\"Workspace not accessible. Change your parameters or create a new workspace\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "##import libraries\nimport keras\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#Import dataset and set it up to train and test sets\nmnist = keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#simplify images /255\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#build model_v1\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(10, activation='softmax')\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Complie the model\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#train the model\nmodel.fit(train_images, train_labels, epochs=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#test the model\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "image = test_images[99]\nplt.imshow(image)\nx = (np.expand_dims(image, 0))\n\npredictions = model.predict(x)\nprint(predictions)\n\nmodel.save('model.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom keras.models import load_model\n\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    # retrieve the path to the model file using the model name\n    model_path = Model.get_model_path('model.h5')\n    model = load_model(model_path)\n\ndef run(raw_data):\n    data = np.asarray(json.loads(raw_data)['data'])\n    return model.predict(data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile myenv.yml\n# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.1\n\n- pip:\n    # Required packages for AzureML execution, history, and data preparation.\n  - azureml-defaults\n- keras\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.image import ContainerImage\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=1, \n                                               tags={\"data\": \"MNIST\",  \"method\" : \"keras\"}, \n                                               description='Predict MNIST with keras')\n\n# configure the image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\")\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='mnist',\n                                       deployment_config=aciconfig,\n                                       models=['model.h5'],\n                                       image_config=image_config)\n\nservice.wait_for_deployment(show_output=True)\n\nprint(service.scoring_uri)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\nprint(x.tolist(), np.asarray(x.tolist()))\ntest_sample = json.dumps({'data': x.tolist()})\ntest_sample = bytes(test_sample,encoding = 'utf8')\n\nprediction = service.run(input_data = test_sample)\nprint(prediction)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}